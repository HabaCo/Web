<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        * {
            font-family: "Microsoft JhengHei", "微軟正黑體", sans-serif;
        }

        body {
            margin: 0;
            height: 100%;
        }

        input,
        button {
            margin: 20 0 50 50;
        }

        #message {
            margin: 0;
            position: fixed;
            bottom: 20;
            width: 100%;
            height: 30%;
            font-size: 1.5em;
            text-align: left;
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            display: flex;
            align-items: center;
            background-color: lightgrey;
            margin: 10px;
            padding: 0px;
            box-sizing: border-box;
            overflow-y: auto;
            box-sizing: border-box;
            border-top: 1px solid #ccc;
        }

        @keyframes bounce {

            0%,
            100% {
                opacity: 0;
            }

            50% {
                opacity: 1;
            }
        }
    </style>
</head>

<body>
    <div id="uploadSection">
        <input type="file" id="uploadFile" placeholder="直接上傳音訊">
    </div>
    <button id="record">whisper - 開始錄音</button>
    <div id="message">訊息會顯示在此處<span id="dots"></span></div>
    <script>

        let isRecording = false;
        let record = document.getElementById('record');
        let uploadFile = document.getElementById('uploadFile');
        let analyser;
        let mediaRecorder;
        let audioChunks = [];
        let soundStopTimer;

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {

                let audioContext = new AudioContext();
                let microphone = audioContext.createMediaStreamSource(stream);

                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;

                let lowPassFilter = audioContext.createBiquadFilter();
                lowPassFilter.type = 'lowpass';
                lowPassFilter.frequency.setValueAtTime(10000, audioContext.currentTime);
                lowPassFilter.Q.setValueAtTime(1, audioContext.currentTime);
                microphone.connect(lowPassFilter);
                lowPassFilter.connect(analyser);
                analyser.connect(audioContext.destination);

                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { 'type': 'audio/ogg; codecs=opus' });
                    audioChunks = [];

                    uploadAudio(audioBlob)
                };

            }).catch(error => {
                console.error("Error accessing media devices.", error);
            });

        function detectSilence() {
            let silenceThreshold = 20
            if (analyser != null) {
                let dataArray = new Uint8Array(analyser.fftSize);
                analyser.getByteTimeDomainData(dataArray);
                let isSilent = dataArray.some(v => Math.abs(v - 128) > silenceThreshold); // silenceThreshold 需要您自行調試設定
                if (isSilent) {
                    // 檢測到聲音
                    if (!isRecording) {
                        console.log('start recording')
                        startRecording();
                        if (soundStopTimer != -1) {
                            clearTimeout(soundStopTimer)
                            soundStopTimer = -1
                        }
                    }
                } else {
                    // 檢測到靜默
                    if (isRecording && soundStopTimer == -1) {
                        soundStopTimer = setTimeout(() => {
                            console.log('stop recording')
                            stopRecording()
                            soundStopTimer = -1
                        }, 1000);
                    }
                }
            }
        }

        setInterval(detectSilence, 100); // 每100毫秒檢查一次

        function startRecording() {
            if (!isRecording) {
                record.textContent = "開始錄音";
                mediaRecorder.start();
                isRecording = true;
            }
        }

        function stopRecording() {
            if (isRecording) {
                record.textContent = "停止錄音";
                mediaRecorder.stop();
                isRecording = false;
            }
        }

        uploadFile.addEventListener('change', function () {
            if (this.files.length > 0) {
                uploadAudio(this.files[0]);
            }
        });

        function uploadAudio(audioBlob) {

            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.ogg');

            fetch('/upload', {
                method: 'POST',
                body: formData,
            })
                .then(response => response.json())
                .then(data => {
                    console.log('Success:', data);

                    let language = data.result.language;
                    let text = data.result.text
                    document.getElementById('message').textContent = `[${language}] ${text}`;
                })
                .catch((error) => {
                    console.error('Error:', error);
                    document.getElementById('message').textContent = 'Error: ' + error;
                });
        }

    </script>
</body>

</html>